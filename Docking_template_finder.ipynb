{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkoorsen/Automatic_multi_docking/blob/main/Docking_template_finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-Xke133sX51",
        "outputId": "e6d34bae-008d-465b-925f-ffc67350a77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/3.1 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m2.8/3.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.22.4)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.81\n"
          ]
        }
      ],
      "source": [
        "!pip install biopython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zkr23ZpwGKj",
        "outputId": "d3ee2961-c203-40e1-b340-800c05c7bd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKYTHKu8sV7L"
      },
      "outputs": [],
      "source": [
        "from Bio.PDB import PDBParser\n",
        "import Bio.PDB as PDB\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "from Bio.Blast import NCBIWWW, NCBIXML\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sV1y0Y3O-Rh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_pdb_file(pdb_id: str) -> str:\n",
        "\n",
        "    PDB_DIR =\"/tmp/pdb/\"\n",
        "    os.makedirs(PDB_DIR, exist_ok=True)\n",
        "\n",
        "    # url or pdb_id\n",
        "    if pdb_id.startswith('http'):\n",
        "        url = pdb_id\n",
        "        filename = url.split('/')[-1]\n",
        "    elif pdb_id.endswith(\".pdb\"):\n",
        "        return pdb_id\n",
        "    else:\n",
        "        if pdb_id.startswith(\"AF\"):\n",
        "            url = f'https://alphafold.ebi.ac.uk/files/{pdb_id}-model_v3.pdb'\n",
        "        else:\n",
        "            url = f'http://files.rcsb.org/view/{pdb_id}.pdb'\n",
        "        filename = f'{pdb_id}.pdb'\n",
        "\n",
        "    cache_path = os.path.join(PDB_DIR, filename)\n",
        "    if os.path.exists(cache_path):\n",
        "        return cache_path\n",
        "\n",
        "    pdb_req = requests.get(url)\n",
        "    pdb_req.raise_for_status()\n",
        "    open(cache_path, 'w').write(pdb_req.text)\n",
        "    return cache_path\n",
        "\n",
        "def find_ligands(pdb_file):\n",
        "\n",
        "    ligand_counts = {}\n",
        "    ligand_names = {}\n",
        "\n",
        "    with open(pdb_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"HETNAM\"):\n",
        "                ligand_code = line[11:14].strip()\n",
        "                ligand_name = line[15:].strip()\n",
        "                ligand_names[ligand_code] = ligand_name\n",
        "                print(ligand_code,ligand_name)\n",
        "            elif line.startswith(\"HET \"):\n",
        "                het_ligand = line[7:10].strip()\n",
        "                chain = line[12].strip()\n",
        "                if het_ligand not in ligand_counts:\n",
        "                    ligand_counts[het_ligand] = {'chain' : [], 'counts' : []}\n",
        "                if chain not in ligand_counts[het_ligand]['chain']:\n",
        "                    ligand_counts[het_ligand]['chain'].append(chain)\n",
        "                    ligand_counts[het_ligand]['counts'].append(1)\n",
        "                else:\n",
        "                    position = ligand_counts[het_ligand]['chain'].index(chain)\n",
        "                    ligand_counts[het_ligand]['counts'][position] += 1\n",
        "\n",
        "    return ligand_names, ligand_counts\n",
        "\n",
        "\n",
        "def analyse_ligands(pdb_files):\n",
        "    pdbs = []\n",
        "    ligs = []\n",
        "    names = []\n",
        "    chains = []\n",
        "    counts = []\n",
        "\n",
        "    for pdb_file in pdb_files:\n",
        "        print(f\"Processing file: {pdb_file}\")\n",
        "        ligand_dict, ligand_count_dict = find_ligands(pdb_file)\n",
        "        print(f\"Ligands found: {list(ligand_dict.items())}\")\n",
        "        for ligand, chains_and_counts in ligand_count_dict.items():\n",
        "            if ligand == ' ':\n",
        "                continue\n",
        "            for chain, count in zip(chains_and_counts['chain'], chains_and_counts['counts']):\n",
        "                pdbs.append(pdb_file[pdb_file.find('/pdb/')+5:pdb_file.find('.pdb')])\n",
        "                ligs.append(ligand)\n",
        "                names.append(ligand_dict.get(ligand, \"Unknown\"))\n",
        "                chains.append(chain)\n",
        "                counts.append(count)\n",
        "    data = pd.DataFrame({\n",
        "        'pdb': pdbs,\n",
        "        'ligand': ligs,\n",
        "        'name': names,\n",
        "        'chain': chains,\n",
        "        'count': counts\n",
        "    })\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def parse_pdb_line(line):\n",
        "    if line.startswith(\"HETNAM\"):\n",
        "        ligand_code = line[11:14].strip()\n",
        "        ligand_name = line[15:].strip()\n",
        "        if not ligand_code:  # Ignore lines where ligand_code is empty\n",
        "            return (None, None, None, None)\n",
        "        return (ligand_code, ligand_name, None, None)\n",
        "    elif line.startswith(\"HET \"):\n",
        "        het_ligand = line[7:10].strip()\n",
        "        chain = line[21].strip()  # Remove any potential space in chain as well\n",
        "        if not het_ligand or not chain:  # Ignore lines where het_ligand or chain is empty\n",
        "            return (None, None, None, None)\n",
        "        return (het_ligand, None, chain, None)\n",
        "    return (None, None, None, None)\n",
        "\n",
        "\n",
        "def find_ligands(pdb_file):\n",
        "\n",
        "    ligand_counts = {}\n",
        "    ligand_names = {}\n",
        "\n",
        "    with open(pdb_file, 'r') as f:\n",
        "        for line in f:\n",
        "            if line.startswith(\"HETNAM\"):\n",
        "                ligand_code = line[11:14].strip()\n",
        "                ligand_name = line[15:].strip()\n",
        "                ligand_names[ligand_code] = ligand_name\n",
        "            elif line.startswith(\"HET \"):\n",
        "                het_ligand = line[7:10].strip()\n",
        "                chain = line[12:13].strip()  # Adjusted here\n",
        "                if het_ligand not in ligand_counts:\n",
        "                    ligand_counts[het_ligand] = {'chain' : [], 'counts' : []}\n",
        "                if chain not in ligand_counts[het_ligand]['chain']:\n",
        "                    ligand_counts[het_ligand]['chain'].append(chain)\n",
        "                    ligand_counts[het_ligand]['counts'].append(1)\n",
        "                else:\n",
        "                    position = ligand_counts[het_ligand]['chain'].index(chain)\n",
        "                    ligand_counts[het_ligand]['counts'][position] += 1\n",
        "\n",
        "    return ligand_names, ligand_counts\n",
        "\n",
        "\n",
        "\n",
        "def find_similar_structure_with_ligand(pdb_id, seq_identity_cutoff):\n",
        "    print(f'Retrieving the protein sequence for {pdb_id[pdb_id.find(\"pdb/\")+4:]}...')\n",
        "    ppb = PDB.PPBuilder()\n",
        "    pdb_id_only = pdb_id.split('/')[-1]  # get only the last part after '/'\n",
        "    structure = PDB.PDBParser().get_structure(pdb_id_only, pdb_id)\n",
        "    for pp in ppb.build_peptides(structure):\n",
        "        sequence = pp.get_sequence()\n",
        "    print(f'Performing a BLAST search using this sequence...')\n",
        "    result_handle = NCBIWWW.qblast(\"blastp\", \"pdb\", sequence)\n",
        "    blast_record = NCBIXML.read(result_handle)\n",
        "    print('Looking at the alignments of each similar structure...')\n",
        "    similar_structures_with_ligands = []\n",
        "    for alignment in blast_record.alignments:\n",
        "        for hsp in alignment.hsps:\n",
        "            seq_identity = hsp.identities / hsp.align_length\n",
        "            if seq_identity < seq_identity_cutoff:\n",
        "                continue\n",
        "            similar_pdb_id = alignment.hit_id.split(\"|\")[1].split(\"_\")[0]\n",
        "            print('Check if the similar structure has a ligand')\n",
        "            time.sleep(5)\n",
        "            pdb_file = download_pdb_file(similar_pdb_id)\n",
        "            ligand_names, ligand_counts = find_ligands(pdb_file)\n",
        "            if set(ligand_names.keys())-set(excluded) != set():\n",
        "                print(f'Structure found: {similar_pdb_id}')\n",
        "                similar_structures_with_ligands.append(similar_pdb_id)\n",
        "    return similar_structures_with_ligands\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = 'output.xlsx'\n",
        "\n",
        "uninteresting_molecules = [\n",
        "    'TRIS(HYDROXYETHYL)AMINOMETHANE',\n",
        "    'SULFATE ION',\n",
        "    'SODIUM ION',\n",
        "    'CALCIUM ION',\n",
        "    'CHLORIDE ION',\n",
        "    'GLYCEROL',\n",
        "    'ZINC ION',\n",
        "    '1,2-ETHANEDIOL',\n",
        "    'DIMETHYL SULFOXIDE',\n",
        "    'MAGNESIUM ION',\n",
        "    'PHOSPHATE ION',\n",
        "    'TETRAFLUOROALUMINATE ION',\n",
        "    'TRIETHYLENE GLYCOL',\n",
        "    'DI(HYDROXYETHYL)ETHER',\n",
        "    'ETHANOL',\n",
        "    'METHANOL',\n",
        "    'WATER',\n",
        "    'PROPANE',\n",
        "    'BETA-MERCAPTOETHANOL',\n",
        "    '1,2-PROPANEDIOL',\n",
        "    'ACETATE ION',\n",
        "    'FORMATE ION',\n",
        "    'NITRATE ION',\n",
        "    'CARBONATE ION',\n",
        "    'MALONATE ION',\n",
        "    'CITRATE ION',\n",
        "    'TARTRATE ION',\n",
        "    'ASCORBATE ION',\n",
        "    'GLUTAMATE ION',\n",
        "    \"ADENOSINE-5'-MONOPHOSPHATE\",\n",
        "    \"GUANOSINE-5'-MONOPHOSPHATE\",\n",
        "    \"CYTIDINE-5'-MONOPHOSPHATE\",\n",
        "    \"THYMIDINE-5'-MONOPHOSPHATE\",\n",
        "    \"URIDINE-5'-MONOPHOSPHATE\",\n",
        "    \"ACETYL GROUP\",\n",
        "    \"AMINO GROUP\",\n",
        "    \"THIOCYANATE ION\",\n",
        "    \"SELENOMETHIONINE\",\n",
        "    \"GLYCEROL\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "wuzY7CKEt3wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(file_name)"
      ],
      "metadata": {
        "id": "fwTcIPeUs2vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jycHmcyO2VFO"
      },
      "outputs": [],
      "source": [
        "PDB_files = []\n",
        "\n",
        "for pdb_id in df['PDB IDs'].dropna():\n",
        "    PDB_files.append(download_pdb_file(pdb_id.strip()))\n",
        "\n",
        "\n",
        "\n",
        "#Initialize set of all PDBs and a set to store those we've already checked\n",
        "all_pdbs = set(PDB_files)\n",
        "checked_pdbs = set()\n",
        "\n",
        "while True:  # This will keep running until we manually break\n",
        "    new_pdbs = set()  # Store any new PDBs we find during this iteration\n",
        "    for pdb in all_pdbs - checked_pdbs:\n",
        "        # Get the data for this PDB\n",
        "        pdb_data = analyse_ligands([pdb])\n",
        "        # Select only the rows corresponding to interesting ligands\n",
        "        interesting_ligand_data = pdb_data[~pdb_data['name'].isin(uninteresting_molecules)]\n",
        "        print(f'{pdb} has the following interesting data {interesting_ligand_data}')\n",
        "        # If there are no interesting ligands, find similar structures\n",
        "        if interesting_ligand_data.empty:\n",
        "            try:\n",
        "                similar_pdb_ids = find_similar_structure_with_ligand(pdb, 0.9)\n",
        "                for new_pdb_id in similar_pdb_ids:\n",
        "                    new_pdb_file = download_pdb_file(new_pdb_id)\n",
        "                    new_pdbs.add(new_pdb_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error occurred while finding similar structures for PDB {pdb}: {e}\")\n",
        "    if not new_pdbs:\n",
        "        break\n",
        "    # Add the new PDBs to our set of all PDBs\n",
        "    all_pdbs.update(new_pdbs)\n",
        "    # Mark the PDBs we've checked during this iteration as checked\n",
        "    checked_pdbs.update(all_pdbs - checked_pdbs)\n",
        "\n",
        "# We can now analyze them all together\n",
        "final_data = analyse_ligands(list(all_pdbs))\n",
        "\n",
        "\n",
        "# Filter out uninteresting ligands\n",
        "interesting_ligand_final_data = final_data[~final_data['name'].isin(uninteresting_molecules)]\n",
        "interesting_ligand_final_data.to_excel(output_file)\n",
        "files.download(output_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}